{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbor for spine injury classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework notebook we use **nearest neighbor classification** to classify back injuries for patients in a hospital, based on measurements of the shape and orientation of their pelvis and spine.\n",
    "\n",
    "The data set contains information from **310** patients. For each patient, there are: six measurements (the x i.e. features) and a label (the y). The label has **3** possible values, `’NO’` (normal), `’DH’` (herniated disk), or `’SL’` (spondilolysthesis). \n",
    "\n",
    "Credits: Edx Machine Learning Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T14:07:23.460059Z",
     "start_time": "2020-03-17T14:07:23.138031Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data set and divide the data into a training set of 248 patients and a separate test set of 62 patients. The following arrays are created:\n",
    "\n",
    "* **`trainx`** : The training data's features, one point per row.\n",
    "* **`trainy`** : The training data's labels.\n",
    "* **`testx`** : The test data's features, one point per row.\n",
    "* **`testy`** : The test data's labels.\n",
    "\n",
    "We will use the training set (`trainx` and `trainy`), with nearest neighbor classification, to predict labels for the test data (`testx`). We will then compare these predictions with the correct labels, `testy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we code the three labels as `0. = ’NO’, 1. = ’DH’, 2. = ’SL’`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T16:07:05.435577Z",
     "start_time": "2020-03-17T16:07:05.418568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data set and code labels as 0 = ’NO’, 1 = ’DH’, 2 = ’SL’\n",
    "labels = [b'NO', b'DH', b'SL']\n",
    "data = np.loadtxt('../Data/NN_Spine/column_3C.dat', converters={6: lambda s: labels.index(s)} )\n",
    "\n",
    "# Separate features from labels\n",
    "x = data[:,0:6]\n",
    "y = data[:,6]\n",
    "\n",
    "# Divide into training and test set\n",
    "training_indices = list(range(0,20)) + list(range(40,188)) + list(range(230,310))\n",
    "test_indices = list(range(20,40)) + list(range(188,230))\n",
    "\n",
    "trainx = x[training_indices,:]\n",
    "trainy = y[training_indices]\n",
    "testx = x[test_indices,:]\n",
    "testy = y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nearest neighbor classification with L2 (*Euclidean*) distance\n",
    "\n",
    "A brute forces nearest neighbor implementation based on Euclidean distance between a test feature and entire training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T17:14:43.883344Z",
     "start_time": "2020-03-17T17:14:43.877341Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_l_dist(x,y, p=2):\n",
    "    '''\n",
    "    computes P normed distance between two arrays\n",
    "    '''\n",
    "    \n",
    "    return (np.sum(abs(x-y)**p))**(1/p)\n",
    "\n",
    "def NN_Euclidean(trainx, trainy, testx):\n",
    "    \n",
    "    '''\n",
    "    A naive algorithm to find the nearest neighbor without any sorting \n",
    "    '''\n",
    "    \n",
    "    if len(testx.shape)> 1: # Recursive call\n",
    "        return np.array(list(map(lambda test_item: NN_Euclidean(trainx, trainy, test_item), testx)))\n",
    "        \n",
    "    distances = [get_l_dist(trainx_instance, testx) for trainx_instance in trainx]\n",
    "    \n",
    "    return trainy[np.argmin(distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T17:14:44.240318Z",
     "start_time": "2020-03-17T17:14:44.109308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of nearest neighbor classifier: %79.03\n"
     ]
    }
   ],
   "source": [
    "testy_L2 = NN_Euclidean(trainx, trainy, testx)\n",
    "## Compute the accuracy\n",
    "accuracy = np.equal(testy_L2, testy)\n",
    "accuracy = float(np.sum(accuracy))/len(testy)\n",
    "\n",
    "print(\"Accuracy of nearest neighbor classifier (Euclidean): %{:.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Nearest neighbor classification with L1 (Manhattan) distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "<font color=\"magenta\">**For you to do:**</font> Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `testx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T17:16:16.089416Z",
     "start_time": "2020-03-17T17:16:16.083423Z"
    }
   },
   "outputs": [],
   "source": [
    "def NN_Manhattan(trainx, trainy, testx):\n",
    "    \n",
    "    '''\n",
    "    A naive algorithm to find the nearest neighbor without any sorting \n",
    "    '''\n",
    "    \n",
    "    if len(testx.shape)> 1: # Recursive call\n",
    "        return np.array(list(map(lambda test_item: NN_Manhattan(trainx, trainy, test_item), testx)))\n",
    "        \n",
    "    distances = [get_l_dist(trainx_instance, testx, p=1) for trainx_instance in trainx]\n",
    "    \n",
    "    return trainy[np.argmin(distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T17:16:16.404408Z",
     "start_time": "2020-03-17T17:16:16.266409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of nearest neighbor classifier (Manhattan): %77.42\n"
     ]
    }
   ],
   "source": [
    "testy_L1 = NN_Manhattan(trainx, trainy, testx)\n",
    "## Compute the accuracy\n",
    "accuracy = np.equal(testy_L1, testy)\n",
    "accuracy = float(np.sum(accuracy))/len(testy)\n",
    "\n",
    "print(\"Accuracy of nearest neighbor classifier (Manhattan): %{:.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a more in depth comparison between the two distance functions, we can use the <font color=\"blue\">*confusion matrix*</font> that is often use to evaluate a classifier.\n",
    "\n",
    "We will now look a bit more deeply into the specific types of errors made by nearest neighbor classification, by constructing the .\n",
    "\n",
    "|         | NO           | DH  | SL |\n",
    "| ------------- |:-------------:| -----:|-----:|\n",
    "| NO     |       |       |       |               |\n",
    "| DH     |       |       |       |               |\n",
    "| SL     |       |       |       |               |\n",
    "\n",
    "Since there are three labels, the confusion matrix is a 3x3 matrix whose rows correspond to the true label and whose columns correspond to the predicted label. For example, the entry at row DH, column SL, contains the number of test points whose correct label was DH but which were classified as SL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:03:25.549180Z",
     "start_time": "2020-03-18T05:03:25.543178Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(testy,testy_fit):\n",
    "    dict_label ={0: 'NO', 1: 'DH', 2: 'SL'} \n",
    "    n_label = len(dict_label)\n",
    "    output = np.zeros((n_label,n_label))\n",
    "    \n",
    "    if len(testy) != len(testy_fit):\n",
    "        raise ValueError('The two data sets must have the same length')\n",
    "        \n",
    "    for predict, true in zip(testy_fit, testy):\n",
    "        output[int(true), int(predict)] +=1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:05:56.693630Z",
     "start_time": "2020-03-18T05:05:56.687630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix nearest neighbor classifier (Manhattan):\n",
      " [[16.  2.  2.]\n",
      " [10. 10.  0.]\n",
      " [ 0.  0. 22.]]\n",
      "Confusion matrix nearest neighbor classifier (Euclidean):\n",
      " [[17.  1.  2.]\n",
      " [10. 10.  0.]\n",
      " [ 0.  0. 22.]]\n"
     ]
    }
   ],
   "source": [
    "L1_cm = confusion_matrix(testy, testy_L1)\n",
    "L2_cm = confusion_matrix(testy, testy_L2)\n",
    "\n",
    "print( 'Confusion matrix nearest neighbor classifier (Manhattan):\\n', L1_neo )\n",
    "\n",
    "print( 'Confusion matrix nearest neighbor classifier (Euclidean):\\n', L2_neo )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Some Observations from the results\n",
    "\n",
    "*Note down the answers to these, since you will need to enter them as part of this week's assignment.*\n",
    "\n",
    "* DH was **most frequently** misclassified by the L1-based nearest neighbor classifier?\n",
    "* SL was **never** misclassified by the L2-based nearest neighbor classifier?\n",
    "* Only one test point had a different prediction between the two classification schemes (based on L1 and L2 distance)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "670px",
    "left": "0px",
    "right": "1145px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
