{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MHadavand/Lessons/blob/master/ML/NearestNeighbour/IntroductionAndExamples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Re7d6T68cd0"
   },
   "source": [
    "# Introduction (Nearest Neighbor )\n",
    "\n",
    "<font color=\"green\">*Nearest neighbor*</font> is one of the oldest machine learning techniques that is often used for classification. The base idea is to find the closets data record(s) to a target data record based on a measure of distance. Euclidean distance is one the alternatives to define the distance which is one of the Minkowski distance ($L_p$ norms) options where p = 2.\n",
    "\n",
    "\n",
    "$X = (x_1, x_2, x_3, ..., x_n) \\;\\;and\\;\\;  Y = (y_1, y_2, y_3, ..., y_n)$\n",
    "\n",
    "$D(X,Y) = (\\sum | x_i - y_i |^{p})^{\\frac{1}{p}}$ \n",
    "\n",
    "\n",
    "Nearest neighbor can also be used to identify collocated data in a cartezian framework. The idea is very simple and there are different algorithm to make the calculation fast based (e.g. Ball Tree K-d Tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:39.853884Z",
     "start_time": "2020-09-22T22:37:37.302284Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "F5HIuuAA8cd1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from ipywidgets import widgets, interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdZJ2MEl8cd5"
   },
   "source": [
    "# Helper functions/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:39.873898Z",
     "start_time": "2020-09-22T22:37:39.857889Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RQpQxeU-8cd5"
   },
   "outputs": [],
   "source": [
    "def image_plot(image, digit, cmap='bone_r', figsize=(5,5), ax=None):\n",
    "    '''\n",
    "    A function to plot images of hand written digits\n",
    "    '''\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    ax.text(0.1,0.92,'Label : {}'.format(digit), fontsize=10, color ='b', transform=ax.transAxes)\n",
    "    _ = ax.imshow(image, cmap='bone_r')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "def image_plot_check(image, predicted_digit, true_digit, cmap='bone_r', figsize=(6,6), ax=None):\n",
    "    '''\n",
    "    A function to plot images of hand written digits\n",
    "    '''\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    \n",
    "    color = 'g' if predicted_digit==true_digit else 'r'\n",
    "    \n",
    "    ax.text(0.1,0.92,'Predicted_Label : {}'.format(predicted_digit), fontsize=10, color =color, transform=ax.transAxes)\n",
    "    _ = ax.imshow(image, cmap='bone_r')\n",
    "    \n",
    "    if predicted_digit!=true_digit:\n",
    "        ax.text(0.7,0.92,'Correct_Label : {}'.format(true_digit), fontsize=10, color ='g', transform=ax.transAxes)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "def get_squared_dist(x,y):\n",
    "    '''\n",
    "    computes squared Euclidean distance between two arrays\n",
    "    '''\n",
    "    return np.sum(np.square(x-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRQFzu1m8cd-"
   },
   "source": [
    "# MNIST Example\n",
    "\n",
    "In this example, nearest neighbor is used to create a classifier that takes images of hand written digits and outputs a label between 0 and 9. MNIST data set is used for this example.\n",
    "\n",
    "MNIST is a classic dataset in machine learning (the hello world example), consisting of 28x28 gray-scale images handwritten digits. The original training set contains 60,000 examples and the test set contains 10,000 examples. In this notebook we will be working with a subset of this data: a training set of 7,500 examples and a test set of 1,000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:40.006890Z",
     "start_time": "2020-09-22T22:37:39.878886Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Gg73OI-P8cd-"
   },
   "outputs": [],
   "source": [
    "## Load the training set\n",
    "train_data = np.load('../Data/MNIST/train_data.npy')\n",
    "train_labels = np.load('../Data/MNIST/train_labels.npy')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = np.load('../Data/MNIST/test_data.npy')\n",
    "test_labels = np.load('../Data/MNIST/test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:40.018922Z",
     "start_time": "2020-09-22T22:37:40.008884Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wHZclTzm8ceE",
    "outputId": "18e43c33-4432-4bc1-b8c9-fa7a7261d51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  7500\n",
      "Number of testing images:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training images: \", np.shape(train_data)[0])\n",
    "print(\"Number of testing images: \", np.shape(test_data)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9gYh62U8ceK"
   },
   "source": [
    "## Visualizing the data set\n",
    "\n",
    "Checking some training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:41.529228Z",
     "start_time": "2020-09-22T22:37:41.139227Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gT4D-l-g8ceM",
    "outputId": "84d74745-fb3d-4854-b200-541f3b6bf29f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0, len(train_labels), 4)\n",
    "for i, ax in zip(idx,axes):\n",
    "    # Note that the data has the flat image array that needs to be reshabed before being plotted\n",
    "    image_plot(train_data[i].reshape(28,-1), train_labels[i], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ykyg2xhE8ceR"
   },
   "source": [
    "## Choose distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tg-8rr0P8ceS"
   },
   "source": [
    "One option is *Euclidean distance*: for two vectors $x, y \\in \\mathbb{R}^d$:\n",
    "\n",
    "$$\\|x - y\\| = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}.$$\n",
    "\n",
    "The square root can be omitted as the distance is used as measure of relative distance, and simply compute _squared Euclidean distance_:\n",
    "\n",
    "$$\\|x - y\\|^2 = \\sum_{i=1}^d (x_i - y_i)^2.$$\n",
    "\n",
    "For the purposes of nearest neighbor computations, the two are equivalent: for three vectors $x, y, z \\in \\mathbb{R}^d$, we have \n",
    "\n",
    "$\\|x - y\\| \\leq \\|x - z\\|$ if and only if $\\|x - y\\|^2 \\leq \\|x - z\\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaAlhQyn8ceU"
   },
   "source": [
    "## Nearest neighbor based on squared Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:43.239172Z",
     "start_time": "2020-09-22T22:37:43.234176Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vRw9ucPP8ceV"
   },
   "outputs": [],
   "source": [
    "def get_nn(input_image, reference_images, reference_labels):\n",
    "    \n",
    "    '''\n",
    "    A naive algorithm to find the nearest neighbor without any sorting\n",
    "    '''\n",
    "    \n",
    "    distances = [get_squared_dist(input_image, ref_image) for ref_image in reference_images]\n",
    "    \n",
    "    return reference_labels[np.argmin(distances)], np.argmin(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:43.783993Z",
     "start_time": "2020-09-22T22:37:43.769949Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4OtIc6td8ced"
   },
   "outputs": [],
   "source": [
    "test_image_index = widgets.BoundedIntText(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=len(test_labels)+1,\n",
    "    step=1,\n",
    "    description='Test Image Index:',\n",
    "    disabled=False,\n",
    "    color='black'\n",
    ")\n",
    "\n",
    "def check_test_image(test_image_index):\n",
    "    \"\"\"\n",
    "    A widget to check test images\n",
    "    \"\"\"\n",
    "    test_image_index = int(test_image_index) - 1\n",
    "    \n",
    "    predicted_digit, predicted_index = get_nn(test_data[test_image_index], train_data, train_labels)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "    \n",
    "    image_plot_check(test_data[test_image_index].reshape(28,-1), \n",
    "                     predicted_digit, true_digit = test_labels[test_image_index],\n",
    "                     ax=axes[0])\n",
    "    axes[0].set_title('Predcition')\n",
    "    image_plot(train_data[predicted_index].reshape(28,-1), train_labels[predicted_index], ax=axes[1])\n",
    "    axes[1].set_title('Nearest Neighbor Training Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:37:44.652950Z",
     "start_time": "2020-09-22T22:37:44.353948Z"
    },
    "colab": {
     "referenced_widgets": [
      "74428a280b434c6887f5971725aa5bf2"
     ]
    },
    "colab_type": "code",
    "id": "48mpgCYs8cei",
    "outputId": "5940f492-5c7c-439b-b46d-39651759febe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471e8c8d8c7b44a2b8c7ec8367382485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=1, description='Test Image Index:', max=1001, min=1), Output()), _d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(check_test_image, test_image_index=test_image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVZ_xO3w8cem"
   },
   "source": [
    "## Process all test images\n",
    "\n",
    "Evaluate the performance of the naive nearest neighbor search and also calculate the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:39:10.824086Z",
     "start_time": "2020-09-22T22:37:57.746092Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EiTDGxqN8ceo",
    "outputId": "c5e00124-1781-4f58-b3a1-4455c8612012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of nearest neighbor classifier: %95.40\n",
      "Classification time (seconds):  73.07199048995972\n"
     ]
    }
   ],
   "source": [
    "## Predict for each test image \n",
    "t_before = time.time()\n",
    "test_predictions = [get_nn(test_data[i],train_data, train_labels)[0] for i in range(len(test_labels))]\n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the accuracy\n",
    "accuracy = np.equal(test_predictions, test_labels)\n",
    "accuracy = float(np.sum(accuracy))/len(test_labels)\n",
    "\n",
    "print(\"Accuracy of nearest neighbor classifier: %{:.2f}\".format(accuracy*100))\n",
    "print(\"Classification time (seconds): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq6itsbr8cer"
   },
   "source": [
    "# Improving the nearest neighbor performance\n",
    "\n",
    "With the naive implementation of nearest neighbor, we need a full pass through the entire training set in order to classify one image. \n",
    "\n",
    "There are faster algorithm to perform nearest neighbor search that is based on preprocessing the training/reference data set. `scikit-learn` has two useful nearest neighbor search algorithms: the _ball tree_ and the _k-d tree_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2snNLCHr8ces"
   },
   "source": [
    "## Ball Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-22T22:38:00.455Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aaOoC5Xg8ces",
    "outputId": "ba1325b3-09e3-4aab-f180-5db9b4aa863d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Build the hyper space partitioning structure (Hyper Spheres). \n",
    "t_before = time.time()\n",
    "ball_tree = BallTree(train_data)\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to build the hyper space partitioning structure(seconds): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-22T22:38:01.759Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "swzCupdc8cew",
    "outputId": "efc45f3b-55f6-4df0-c5e2-5d39edb38334"
   },
   "outputs": [],
   "source": [
    "## Get nearest neighbor predictions on testing data\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\n",
    "ball_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the accuracy\n",
    "accuracy = np.equal(ball_tree_predictions, test_labels)\n",
    "accuracy = float(np.sum(accuracy))/len(test_labels)\n",
    "\n",
    "print(\"Accuracy of nearest neighbor classifier: %{:.2f}\".format(accuracy*100))\n",
    "print(\"Classification time (seconds): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJg1ud7V8ce1"
   },
   "source": [
    "AS can be seen above, the ball-tree search provides the same accuracy and is significantly faster than the naive nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avMDhKdO8ce1"
   },
   "source": [
    "## KDTree (k-dimensional tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-22T22:38:03.656Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "J0rRXJiz8ce2"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-22T22:38:03.958Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Hr0JN-3D8ce5",
    "outputId": "bfca19ad-6b74-4ea1-ec46-0703b15c98f1"
   },
   "outputs": [],
   "source": [
    "# Build the hyper space partitioning structure. \n",
    "t_before = time.time()\n",
    "kd_tree = KDTree(train_data, leaf_size=40, metric='minkowski', p=2)\n",
    "t_after = time.time()\n",
    "\n",
    "print(\"Time to build the hyper space partitioning structure(seconds): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-22T22:38:04.584Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "w_qKSc7X8ce-",
    "outputId": "9e24c17f-2d2c-40de-d678-bd442516c775"
   },
   "outputs": [],
   "source": [
    "## Get nearest neighbor predictions on testing data\n",
    "t_before = time.time()\n",
    "test_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\n",
    "ball_tree_predictions = train_labels[test_neighbors]\n",
    "t_after = time.time()\n",
    "\n",
    "## Compute the accuracy\n",
    "accuracy = np.equal(ball_tree_predictions, test_labels)\n",
    "accuracy = float(np.sum(accuracy))/len(test_labels)\n",
    "\n",
    "print(\"Accuracy of nearest neighbor classifier: %{:.2f}\".format(accuracy*100))\n",
    "print(\"Classification time (seconds): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjzA-cPh8cfA"
   },
   "source": [
    "# Improving the nearest neighbor\n",
    "\n",
    "One option is the use multiple nearest neighbors (i.e. KNN) and use the majority rule decision. K-Fold cross-validation analysis can be used to select the optimal number for K.\n",
    "\n",
    "The better approach is to use the proper distance function. For example, for image classification like the MNIST example, Minkowski distances are proper choice as they are sensitive to moving/rotating the target object (e.g. hand written number) in the image. \n",
    "\n",
    "**Tangent distance** is not sensitive to small translations and rotations.\n",
    "\n",
    "**Shape context**, can be used to handle a broader family of natural deformations.\n",
    "\n",
    "Another distance function that is a metric is an edit distance that is the number of insertions, deletions and substitutions to get from instance X to instance y. This kind of distance function is particularly suitable for string arrays."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "IntroductionAndExamples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
